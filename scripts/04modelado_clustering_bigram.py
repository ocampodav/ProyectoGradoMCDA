# -*- coding: utf-8 -*-
"""04Modelado_Clustering_Bigram.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p2jTC3NS8zMO3uTTrYjuwPVNfDibgwuN

# **Modelo no Supervisado (K-Means)**

**Preparar notebook**
"""

## Conectar el notebook a googledrive
#from google.colab import drive
#drive.mount('/content/drive')

## Importar librerias necesarias
import nltk
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
from nltk import bigrams

"""**Cargar los Datos Preparados**"""

df = pd.read_csv('/content/datos.csv', encoding='latin-1')
df.shape

## Recuperar los tokes (como lista) que se extrajeron en el textprep y que al exportar el archivo .csv se cargaron como cadenas de texto
df['tokens_proc'] = df['tokens_proc'].apply(lambda x: re.sub('[\[\]\']+', '', str(x)))
df['tokens_proc'] = df['tokens_proc'].apply(lambda x: x.split(', '))

df=df[['WORKLOGID','DETALLE', 'tokens_proc']]

df

df_tfidf_bigram = pd.read_csv('/content/tfidf_bigram.csv', encoding='latin-1')
df_tfidf_bigram.head()

df_tfidf_bigram.drop(['Unnamed: 0'], axis = 1, inplace=True)

df_tfidf_bigram

"""## Reducción de dimensionalidad

**PCA**
"""

from sklearn.decomposition import PCA

"""Análisis de componentes principales sobre representación vectorial de bigramas"""

n_componentes = 10
pca = PCA(n_components=n_componentes)
PrincipalComponents = pca.fit_transform(df_tfidf_bigram)

componentes = pca.fit(df_tfidf_bigram).components_

print(np.round(pca.explained_variance_ratio_, 6))
plt.figure(figsize = (4, 4))
plt.bar(np.arange(n_componentes), pca.explained_variance_ratio_)
plt.title("Varianza explicada por las componentes")
plt.show()

var_acum = np.cumsum(pca.explained_variance_ratio_)
print(var_acum)
plt.figure(figsize = (4, 4))
plt.plot(var_acum)
plt.title("Varianza acumulada de las componentes principales")
plt.show()

componentes = pd.DataFrame(componentes).transpose()
componentes.columns = pca.get_feature_names_out()
componentes.index =  df_tfidf_bigram.columns
print(componentes)

componentes['pca0'].sort_values(ascending = False)

principalDf = pd.DataFrame(data = PrincipalComponents)

principalDf

x = principalDf[0]
y = principalDf[1]
z = principalDf[2]
plt.figure(figsize = (5, 5))
plot_axes = plt.axes(projection = '3d')
plot_axes.scatter3D(x, y, z)
plot_axes.set_xlabel('Componente 1')
plot_axes.set_ylabel('Componente 2')
plot_axes.set_zlabel('Componente 3')
plt.show()

"""**t-SNE**"""

from sklearn.manifold import TSNE

"""Análisis sobre representación vectorial de bigramas"""

bigrams_embedded_1 = TSNE(n_components=3, learning_rate=10, init='random', random_state = 42, n_iter = 500).fit_transform(df_tfidf_bigram)
#Tarda alrededor de 7min

tSNEdf1 = pd.DataFrame(data = bigrams_embedded_1)

x = tSNEdf1[0]
y = tSNEdf1[1]
z = tSNEdf1[2]
plt.figure(figsize = (5, 5))
plot_axes = plt.axes(projection = '3d')
plot_axes.scatter3D(x, y, z)
plot_axes.set_xlabel('Componente 1')
plot_axes.set_ylabel('Componente 2')
plot_axes.set_zlabel('Componente 3')
plt.show()

bigrams_embedded_2 = TSNE(n_components=3, learning_rate=1000, init='random', random_state = 42, n_iter = 500).fit_transform(df_tfidf_bigram)
#Tarda alrededor de 7min

tSNEdf2 = pd.DataFrame(data = bigrams_embedded_2)

x = tSNEdf2[0]
y = tSNEdf2[1]
z = tSNEdf2[2]
plt.figure(figsize = (5, 5))
plot_axes = plt.axes(projection = '3d')
plot_axes.scatter3D(x, y, z)
plot_axes.set_xlabel('Componente 1')
plot_axes.set_ylabel('Componente 2')
plot_axes.set_zlabel('Componente 3')
plt.show()

bigrams_embedded_3 = TSNE(n_components=3, learning_rate=1000, init='random', random_state = 42, n_iter = 500, perplexity=50.0).fit_transform(df_tfidf_bigram)
#Tarda alrededor de 7min

tSNEdf3 = pd.DataFrame(data = bigrams_embedded_3)

x = tSNEdf3[0]
y = tSNEdf3[1]
z = tSNEdf3[2]
plt.figure(figsize = (5, 5))
plot_axes = plt.axes(projection = '3d')
plot_axes.scatter3D(x, y, z)
plot_axes.set_xlabel('Componente 1')
plot_axes.set_ylabel('Componente 2')
plot_axes.set_zlabel('Componente 3')
plt.show()

"""## Modelado

**kmeans**
"""

from sklearn.cluster import KMeans
from sklearn import metrics
from sklearn.metrics import pairwise_distances_argmin_min

"""Crear el modelo sobre las componentes principales"""

ks = range(2, 20)
inertias = []
siluetas = []

for k in ks:
    # Crear  modelo
    model = KMeans(n_clusters=k,  n_init = 10, max_iter=500,)
    model.fit(principalDf)
    inertias.append(model.inertia_)
    siluetas.append(metrics.silhouette_score(principalDf, model.labels_))

"""Identificación del número optimo de clusters mediante métricas de **inercia** y **silueta**"""

# Graficar cantidad de clusters vs inertias
plt.plot(ks, inertias, '-o')
plt.xlabel('Numero de clusters, k')
plt.ylabel('inertia')
plt.title("Inercia Vs Número de Clusters")
plt.xticks(ks)
plt.show()

# Graficar cantidad de clusters vs inertias
plt.plot(ks, siluetas, '-o')
plt.xlabel('Numero de clusters, k')
plt.ylabel('Silueta')
plt.title("Silueta Vs Número de Clusters")
plt.xticks(ks)
plt.show()

"""###Modelo óptimo

Para un número de clusters k=12, según el método del codo
"""

k=12
kmeans_pca = KMeans(n_clusters=k, max_iter=500, n_init = 10)
kmeans_pca.fit(principalDf)

print('Inercia= {}'.format(kmeans_pca.inertia_))
print('Silueta= {}'. format(metrics.silhouette_score(principalDf, kmeans_pca.labels_)))

# k=12
# kmeans_bigrams = KMeans(n_clusters=k, max_iter=500, n_init = 10)
# kmeans_bigrams.fit(df_tfidf_bigram)

# print('Inercia= {}'.format(kmeans_bigrams.inertia_))
# print('Silueta= {}'. format(metrics.silhouette_score(df_tfidf_bigram, kmeans_bigrams.labels_)))

x = principalDf[0]
y = principalDf[1]
z = principalDf[2]

color = ['gray', 'blue','red','green','purple','cyan','yellow', 'black', 'orange', 'olive', 'pink', 'violet']
c=[]
for i in kmeans_pca.labels_:
  c.append(color[i])

plt.figure(figsize = (5, 5))
plot_axes = plt.axes(projection = '3d')
plot_axes.scatter3D(x, y, z, c=c)

plot_axes.set_xlabel('Componente 1')
plot_axes.set_ylabel('Componente 2')
plot_axes.set_zlabel('Componente 3')

plt.figure(figsize = (4, 4))
plt.scatter(x, z, c=c)
plt.xlabel('Componente 1')
plt.ylabel('Componente 2')
plt.show()

plt.figure(figsize = (4, 4))
plt.scatter(x, y, c=c)
plt.xlabel('Componente 1')
plt.ylabel('Componente 3')
plt.show()

plt.figure(figsize = (4, 4))
plt.scatter(y, z, c=c)
plt.xlabel('Componente 2')
plt.ylabel('Componente 3')
plt.show()

"""Centroides de los clusters"""

centroides=pd.DataFrame(kmeans_pca.cluster_centers_, columns=principalDf.columns.values)

#vemos el representante del grupo, el registro cercano al centroide de su cluster
mas_cercano, _ = pairwise_distances_argmin_min(kmeans_pca.cluster_centers_, principalDf)
mas_cercano

"""###Analisis de los resultados

Asignar etiquetas de los clusters al conjunto de los datos
"""

df['label'] = kmeans_pca.labels_
df.head()

"""Cantidad de registros por cluster"""

df['label'].value_counts()

"""Registros más cercanos a los centroides de los clusters"""

df.iloc[mas_cercano]

"""Obtener los bigramas presentes en los registros más cercanos a los centroides"""

bigrams_centroides = []
for i in mas_cercano:
  serie = df_tfidf_bigram.iloc[i]
  bigrams_centroides.append(serie[serie > 0].index.values.tolist())

"""para uno de los clusters"""

bigrams_centroides

bigrams_centroides[1]

"""Analisis de frecuencia de los bigramas en los conjuntos de datos correspondientes a cada cluster"""

#Obtener los 20 bigramas más frecuentes en cada subconjunto de datos (cluster)
m = 10
for i in range(k):
  cluster = df[df['label']==i]
  tokens_cluster = []
  for t in cluster['tokens_proc']:
      tokens_cluster.extend(t)
  fdist_bigrams_cluster = nltk.FreqDist(bigrams(tokens_cluster))
  top_bigrams_cluster = fdist_bigrams_cluster.most_common(m)
  tuplas = [t for t, v in top_bigrams_cluster]
  valores = [v for t, v in top_bigrams_cluster]
  print('______________________________________________________________________')
  print('Top {} bigramas más comunes en registros del cluster {}'.format(m,i))
  plt.figure(figsize=(5,3))
  plt.title('Top {} bigramas más comunes en registros del cluster {}'.format(m,i))
  plt.bar([', '.join(tupla) for tupla in tuplas],valores)
  plt.xticks(rotation=90)
  plt.show()